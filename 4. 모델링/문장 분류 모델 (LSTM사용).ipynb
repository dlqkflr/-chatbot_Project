{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_morph_df = pd.read_csv('morph_text.csv', encoding='utf-8')\n",
    "text_nouns_df = pd.read_csv('noun_text.csv', encoding='utf-8')\n",
    "label_df = pd.read_csv('classifi_corpus_label.csv', encoding='utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame()\n",
    "data_df['ntext'] = text_nouns_df['text']\n",
    "data_df['mtext'] = text_morph_df['text']\n",
    "data_df['label'] = label_df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index_to_word_byOkt.pickle', 'rb') as f :\n",
    "    index_to_word = pickle.load(f)\n",
    "with open('index_to_noums_byOkt.pickle', 'rb') as f :\n",
    "    index_to_noums = pickle.load(f)\n",
    "with open('word_to_index_byOkt.pickle', 'rb') as f :\n",
    "    word_to_index = pickle.load(f)\n",
    "with open('noums_to_index_byOkt.pickle', 'rb') as f :\n",
    "    noums_to_index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9997, 9997), (9999, 9999))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(index_to_word), len(word_to_index)), (len(index_to_noums), len(noums_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_df = data_df.drop('mtext', axis= 1)\n",
    "mor_data_df = data_df.drop('ntext', axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_df = num_data_df.dropna()\n",
    "mor_data_df = mor_data_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_df.ntext = num_data_df.ntext.apply(lambda x: x.split())\n",
    "mor_data_df.mtext = mor_data_df.mtext.apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어 -> 인덱스 변환\n",
    "def n_to_int(x):\n",
    "    pad_index = []\n",
    "    for i in x:\n",
    "        pad_index.append(noums_to_index[i])\n",
    "    return pad_index\n",
    "\n",
    "#morph -> 인덱스 변환\n",
    "def w_to_int(x):\n",
    "    pad_index = []\n",
    "    for i in x:\n",
    "        pad_index.append(word_to_index[i])\n",
    "    return pad_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_X = num_data_df.ntext.apply(lambda x: n_to_int(x))\n",
    "mor_X = mor_data_df.mtext.apply(lambda x: w_to_int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2860 2329 8723 9849 4787  391    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [6440 8723 9849 4467 7516    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [6440 8723 9849 4467 7516    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [7241  359    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [3267 8723 3884 1464 3742 5649 4380    0    0    0    0    0    0    0\n",
      "     0]]\n",
      "[[1733 4535 3053 3843 6070  637  889  755    0    0    0    0    0    0\n",
      "     0]\n",
      " [1910 3053 3843 9477 5769 4793    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [1910 3053 3843 9477 5769 4793    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [7808   61 3688    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [ 169 3053 4934 3923 2480 1667 2248 4346  169 3390 8004 9250 5123 7137\n",
      "   158]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_nom =pad_sequences(nom_X, maxlen=15, padding='post', truncating='pre')\n",
    "X_mor =pad_sequences(mor_X, maxlen=15, padding='post', truncating='pre')\n",
    "\n",
    "\n",
    "print(X_nom[:5])\n",
    "print(X_mor[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250614, 15), (256913, 15))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_nom.shape , X_mor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_num = num_data_df['label'].values\n",
    "Y_mor = mor_data_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_n_train, x_n_test, y_n_train, y_n_test = train_test_split(X_nom, Y_num, test_size = 0.2, random_state = 77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200491, 15), (200491,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_n_train.shape, y_n_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "from keras.layers import LSTM\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(9999, 32,input_length=15))\n",
    "model1.add(LSTM(64, return_sequences= True))\n",
    "model1.add(LSTM(32))\n",
    "model1.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 160392 samples, validate on 40099 samples\n",
      "Epoch 1/10\n",
      "160392/160392 [==============================] - 33s 205us/step - loss: 0.2416 - acc: 0.9161 - val_loss: 0.2264 - val_acc: 0.9214\n",
      "Epoch 2/10\n",
      "160392/160392 [==============================] - 33s 205us/step - loss: 0.2023 - acc: 0.9261 - val_loss: 0.2140 - val_acc: 0.9245\n",
      "Epoch 3/10\n",
      "160392/160392 [==============================] - 33s 204us/step - loss: 0.1883 - acc: 0.9308 - val_loss: 0.2153 - val_acc: 0.9245\n",
      "Epoch 4/10\n",
      "160392/160392 [==============================] - 34s 209us/step - loss: 0.1775 - acc: 0.9349 - val_loss: 0.2161 - val_acc: 0.9247\n",
      "Epoch 5/10\n",
      "160392/160392 [==============================] - 34s 210us/step - loss: 0.1677 - acc: 0.9385 - val_loss: 0.2202 - val_acc: 0.9232\n",
      "Epoch 6/10\n",
      "160392/160392 [==============================] - 32s 200us/step - loss: 0.1579 - acc: 0.9420 - val_loss: 0.2349 - val_acc: 0.9231\n",
      "Epoch 7/10\n",
      "160392/160392 [==============================] - 32s 201us/step - loss: 0.1486 - acc: 0.9457 - val_loss: 0.2313 - val_acc: 0.9246\n",
      "Epoch 8/10\n",
      "160392/160392 [==============================] - 37s 229us/step - loss: 0.1393 - acc: 0.9494 - val_loss: 0.2508 - val_acc: 0.9263\n",
      "Epoch 9/10\n",
      "160392/160392 [==============================] - 35s 216us/step - loss: 0.1304 - acc: 0.9523 - val_loss: 0.2655 - val_acc: 0.9209\n",
      "Epoch 10/10\n",
      "160392/160392 [==============================] - 34s 210us/step - loss: 0.1229 - acc: 0.9551 - val_loss: 0.2482 - val_acc: 0.9288\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss= 'binary_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
    "history = model1.fit(x_n_train, y_n_train, batch_size =128, epochs =10 , validation_split =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_m_train, x_m_test, y_m_train, y_m_test = train_test_split(X_mor, Y_mor, test_size = 0.2, random_state = 77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "from keras.layers import LSTM\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(9997, 32,input_length=15))\n",
    "model2.add(LSTM(64, return_sequences= True))\n",
    "model2.add(LSTM(32))\n",
    "model2.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 164424 samples, validate on 41106 samples\n",
      "Epoch 1/10\n",
      "164424/164424 [==============================] - 32s 192us/step - loss: 0.2230 - acc: 0.9192 - val_loss: 0.1898 - val_acc: 0.9274\n",
      "Epoch 2/10\n",
      "164424/164424 [==============================] - 30s 182us/step - loss: 0.1755 - acc: 0.9314 - val_loss: 0.1832 - val_acc: 0.9312\n",
      "Epoch 3/10\n",
      "164424/164424 [==============================] - 29s 179us/step - loss: 0.1565 - acc: 0.9384 - val_loss: 0.1806 - val_acc: 0.9323\n",
      "Epoch 4/10\n",
      "164424/164424 [==============================] - 33s 200us/step - loss: 0.1398 - acc: 0.9450 - val_loss: 0.1832 - val_acc: 0.9335\n",
      "Epoch 5/10\n",
      "164424/164424 [==============================] - 32s 195us/step - loss: 0.1240 - acc: 0.9517 - val_loss: 0.1935 - val_acc: 0.9359\n",
      "Epoch 6/10\n",
      "164424/164424 [==============================] - 31s 191us/step - loss: 0.1090 - acc: 0.9575 - val_loss: 0.1960 - val_acc: 0.9361\n",
      "Epoch 7/10\n",
      "164424/164424 [==============================] - 31s 191us/step - loss: 0.0958 - acc: 0.9635 - val_loss: 0.2035 - val_acc: 0.9372\n",
      "Epoch 8/10\n",
      "164424/164424 [==============================] - 35s 212us/step - loss: 0.0849 - acc: 0.9677 - val_loss: 0.2199 - val_acc: 0.9331\n",
      "Epoch 9/10\n",
      "164424/164424 [==============================] - 36s 219us/step - loss: 0.0755 - acc: 0.9714 - val_loss: 0.2444 - val_acc: 0.9340\n",
      "Epoch 10/10\n",
      "164424/164424 [==============================] - 35s 211us/step - loss: 0.0668 - acc: 0.9745 - val_loss: 0.2446 - val_acc: 0.9393\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss= 'binary_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
    "history = model1.fit(x_m_train, y_m_train, batch_size =128, epochs =10 , validation_split =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50123/50123 [==============================] - 5s 106us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7555449545238375, 0.8393751371613909]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(x_n_test, y_n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51383/51383 [==============================] - 5s 104us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6910165342005722, 0.8018021524547567]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_m_test, y_m_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
